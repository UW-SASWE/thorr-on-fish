{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from dataretrieval import nwis\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path(\"../../..\")\n",
    "\n",
    "data_dir = proj_dir / \"data/insitu/conditions\"\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# load metadata\n",
    "stations_metadata_path = Path(proj_dir, \"data/insitu/metadata/stations.csv\")\n",
    "stations_attributes_path = Path(proj_dir, \"data/insitu/metadata/dictionaries/stations_attributes.csv\")\n",
    "\n",
    "stations_attributes = pd.read_csv(stations_attributes_path)\n",
    "\n",
    "if not os.path.exists(stations_metadata_path):\n",
    "    stations_metadata = pd.DataFrame(columns=stations_attributes['Attribute_name'])\n",
    "    stations_metadata.to_csv(stations_metadata_path, index=False)\n",
    "\n",
    "stations_metadata = pd.read_csv(stations_metadata_path)\n",
    "\n",
    "target_parameters = {\n",
    "    \"00010_Maximum\": \"max_temp(C)\",\n",
    "    \"00010_Minimum\": \"min_temp(C)\",\n",
    "    \"00010_Mean\": \"avg_temp(C)\",\n",
    "    \"00060_Mean\": \"avg discharge (cfs)\",\n",
    "}\n",
    "\n",
    "parameter_codes = {\n",
    "    \"max water temperature (C)\": \"Maximum water temperature, degrees Celsius\",\n",
    "    \"min water temperature (C)\": \"Minimum water temperature, degrees Celsius\",\n",
    "    \"avg water temperature (C)\": \"Mean water temperature, degrees Celsius\",\n",
    "    \"avg discharge (cfs)\": \"Discharge, cubic feet per second\",\n",
    "    \"avg discharge (m3/d)\": \"Discharge, cubic meters per day\",\n",
    "}\n",
    "\n",
    "startDt = \"1982-08-01\"\n",
    "endDt = \"2024-02-26\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Null layer: 'Basins'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the basin vector data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m basin_gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproj_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/GIS/columbia_river_basin.gpkg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBasins\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# divide the bounding box into 16 smaller boxes\u001b[39;00m\n\u001b[1;32m      5\u001b[0m xmin, ymin, xmax, ymax \u001b[38;5;241m=\u001b[39m basin_gdf\u001b[38;5;241m.\u001b[39mbounds\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hydrothermal-history/lib/python3.11/site-packages/geopandas/io/file.py:281\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hydrothermal-history/lib/python3.11/site-packages/geopandas/io/file.py:322\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[1;32m    323\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hydrothermal-history/lib/python3.11/site-packages/fiona/env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hydrothermal-history/lib/python3.11/site-packages/fiona/__init__.py:292\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    304\u001b[0m         path,\n\u001b[1;32m    305\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hydrothermal-history/lib/python3.11/site-packages/fiona/collection.py:243\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:601\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Null layer: 'Basins'"
     ]
    }
   ],
   "source": [
    "# Load the basin vector data\n",
    "basin_gdf = gpd.read_file(proj_dir / \"data/GIS/dams-temp-fish.gpkg\", layer=\"Basins\")\n",
    "\n",
    "# divide the bounding box into 16 smaller boxes\n",
    "xmin, ymin, xmax, ymax = basin_gdf.bounds.values[0]\n",
    "x = np.linspace(xmin, xmax, 5)\n",
    "y = np.linspace(ymin, ymax, 5)\n",
    "\n",
    "# create a list of lists for the bounding boxes\n",
    "bb = []\n",
    "for i in range(len(x) - 1):\n",
    "    for j in range(len(y) - 1):\n",
    "        bb.append(list(np.array([x[i], y[j], x[i + 1], y[j + 1]]).round(6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sites for each of the bounding boxes and save them to a dataframe\n",
    "siteList = []\n",
    "for i in range(len(bb)):\n",
    "    try:\n",
    "        siteList.append(nwis.what_sites(bBox=bb[i], startDt=startDt, endDt=endDt, parameterCd='00010')[0])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "siteList_df = pd.concat(siteList, ignore_index=True)\n",
    "\n",
    "filtered_sites = gpd.GeoDataFrame(siteList_df, geometry=gpd.points_from_xy(siteList_df['dec_long_va'], siteList_df['dec_lat_va']), crs='epsg:4326')\n",
    "sites_within_basin = filtered_sites[filtered_sites.within(basin_gdf.geometry[0])]\n",
    "# sites_within_basin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save sites_within_basin to a csv file\n",
    "# sites_within_basin.to_csv(Path(data_dir, \"processed\", \"sites_within_basin2.csv\"), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data of filtered sites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in sites_within_basin[\"site_no\"]:\n",
    "# for site in ['12301933']:\n",
    "    # for site in [\"14070615\", \"14070620\", \"14070621\"]:\n",
    "    try:\n",
    "        site_data = nwis.get_record(sites=site, service=\"dv\", start=startDt, end=endDt)\n",
    "        site_data.index.rename(\"date\", inplace=True)\n",
    "        column_dict = {\n",
    "            col: target_parameters[col]\n",
    "            for col in site_data.columns\n",
    "            if col in target_parameters.keys()\n",
    "        }\n",
    "        site_data.rename(\n",
    "            columns=column_dict,\n",
    "            inplace=True,\n",
    "        )\n",
    "        if \"avg discharge (cfs)\" in site_data.columns:\n",
    "            site_data[\"outflow(m3/d)\"] = (\n",
    "                site_data[\"avg discharge (cfs)\"] * 0.0283168 * 86400\n",
    "            )\n",
    "            column_dict[\"outflow(m3/d)\"] = \"outflow(m3/d)\"\n",
    "\n",
    "        if column_dict:\n",
    "            site_data[column_dict.values()].to_csv(\n",
    "                Path(data_dir, \"processed\", f\"USGS_{site}.csv\"), index=True\n",
    "            )\n",
    "\n",
    "            # update metadata\n",
    "            station_ID = \"USGS_\" + site.upper()\n",
    "\n",
    "            if station_ID not in stations_metadata[\"station_ID\"].values:\n",
    "                stations_metadata = pd.concat(\n",
    "                    [\n",
    "                        stations_metadata,\n",
    "                        pd.DataFrame(\n",
    "                            {\n",
    "                                \"station_ID\": [station_ID],\n",
    "                                \"id_at_source\": [site.upper()],\n",
    "                                \"available_data\": [\"{}\"],\n",
    "                                \"source_URL\": ['{\"url\" : []}'],\n",
    "                                \"description\": [\n",
    "                                    sites_within_basin[\n",
    "                                        sites_within_basin[\"site_no\"] == site\n",
    "                                    ][\"station_nm\"].values[0]\n",
    "                                ],\n",
    "                                \"latitude\": [\n",
    "                                    sites_within_basin[\n",
    "                                        sites_within_basin[\"site_no\"] == site\n",
    "                                    ][\"dec_lat_va\"].values[0]\n",
    "                                ],\n",
    "                                \"longitude\": [\n",
    "                                    sites_within_basin[\n",
    "                                        sites_within_basin[\"site_no\"] == site\n",
    "                                    ][\"dec_long_va\"].values[0]\n",
    "                                ],\n",
    "                                \"site_params\": [\"{}\"],\n",
    "                            }\n",
    "                        ),\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                )\n",
    "\n",
    "            # update source url\n",
    "            source_url = json.loads(\n",
    "                stations_metadata.loc[\n",
    "                    stations_metadata[\"station_ID\"] == station_ID, \"source_URL\"\n",
    "                ].values[0]\n",
    "            )\n",
    "\n",
    "            if (\n",
    "                f\"https://waterdata.usgs.gov/monitoring-location/{site}\"\n",
    "                not in source_url[\"url\"]\n",
    "            ):\n",
    "                source_url[\"url\"].append(\n",
    "                    f\"https://waterdata.usgs.gov/monitoring-location/{site}\"\n",
    "                )\n",
    "                stations_metadata.loc[\n",
    "                    stations_metadata[\"station_ID\"] == station_ID, \"source_URL\"\n",
    "                ] = json.dumps(source_url)\n",
    "\n",
    "            # update the available data\n",
    "            availble_data = stations_metadata.loc[\n",
    "                stations_metadata[\"station_ID\"] == station_ID, \"available_data\"\n",
    "            ].values[0]\n",
    "            availble_data = json.loads(availble_data)\n",
    "\n",
    "            # check if there is \"conditions\"  in the available data\n",
    "            if \"conditions\" not in availble_data.values():\n",
    "                availble_data[\"conditions\"] = []\n",
    "            # add the parameters to the available data\n",
    "            # print(parameters[1:])\n",
    "            for param in column_dict.values():\n",
    "                if param not in availble_data[\"conditions\"]:\n",
    "                    availble_data[\"conditions\"].append(param)\n",
    "\n",
    "            # update the metadata\n",
    "            stations_metadata.loc[\n",
    "                stations_metadata[\"station_ID\"] == station_ID, \"available_data\"\n",
    "            ] = json.dumps(availble_data)\n",
    "\n",
    "            # save the metadata\n",
    "            stations_metadata.to_csv(stations_metadata_path, index=False)\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add last updated date and last updated by\n",
    "metadata_status = {\n",
    "    \"last_updated\": pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"update_message\": \"Updated the metadata for USGS stations\",\n",
    "    \"last_updated_by\": \"George Darkwah\",\n",
    "    \"last_updated_by_email\": \"gdarkwah@uw.edu\",\n",
    "}\n",
    "\n",
    "# save metadata\n",
    "with open(Path(proj_dir, \"data/insitu/metadata/metadata_status.csv\"), \"w\") as f:\n",
    "    json.dump(metadata_status, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8c3a16aaf85adb3ca8a1f18e5810b57687b3d06c4b994ba211aab8278e804c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
