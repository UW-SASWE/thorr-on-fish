{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnary_df = pd.read_csv(proj_dir / \"Data/insitu/fish/processed/DART_MCN.csv\")\n",
    "priest_rapids_df = pd.read_csv(proj_dir / \"Data/insitu/fish/processed/DART_PRD.csv\")\n",
    "prosser_df = pd.read_csv(proj_dir / \"Data/insitu/fish/processed/DART_PRO.csv\")\n",
    "ice_harbor_df = pd.read_csv(proj_dir / \"Data/insitu/fish/processed/DART_IHR.csv\")\n",
    "\n",
    "mcnary_df[\"date\"] = pd.to_datetime(mcnary_df[\"date\"])\n",
    "priest_rapids_df[\"date\"] = pd.to_datetime(priest_rapids_df[\"date\"])\n",
    "prosser_df[\"date\"] = pd.to_datetime(prosser_df[\"date\"])\n",
    "ice_harbor_df[\"date\"] = pd.to_datetime(ice_harbor_df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnary_df['year'] = mcnary_df['date'].dt.year\n",
    "priest_rapids_df['year'] = priest_rapids_df['date'].dt.year\n",
    "prosser_df['year'] = prosser_df['date'].dt.year\n",
    "ice_harbor_df['year'] = ice_harbor_df['date'].dt.year\n",
    "\n",
    "mcnary_df['month'] = mcnary_df['date'].dt.month\n",
    "priest_rapids_df['month'] = priest_rapids_df['date'].dt.month\n",
    "prosser_df['month'] = prosser_df['date'].dt.month\n",
    "ice_harbor_df['month'] = ice_harbor_df['date'].dt.month\n",
    "\n",
    "mcnary_df['day'] = mcnary_df['date'].dt.day\n",
    "priest_rapids_df['day'] = priest_rapids_df['date'].dt.day\n",
    "prosser_df['day'] = prosser_df['date'].dt.day\n",
    "ice_harbor_df['day'] = ice_harbor_df['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviation data\n",
    "deviation_df = pd.DataFrame(columns=['Date'])\n",
    "\n",
    "for rkm in range(450, 650, 10):\n",
    "    deviation = pd.read_csv(proj_dir / f\"Data/database/deviations/{rkm}.csv\")\n",
    "    deviation['Date'] = pd.to_datetime(deviation['Date'])\n",
    "    deviation[rkm] = deviation['Deviation']\n",
    "    deviation_df = pd.merge(deviation_df, deviation[['Date', rkm]], on='Date', how='outer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeup_year = 2000\n",
    "mcnary_df_closeup = mcnary_df[(mcnary_df['date'] >= f'{closeup_year}-08-01') & (mcnary_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "priest_rapids_df_closeup = priest_rapids_df[(priest_rapids_df['date'] >= f'{closeup_year}-08-01') & (priest_rapids_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "prosser_df_closeup = prosser_df[(prosser_df['date'] >= f'{closeup_year}-08-01') & (prosser_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "ice_harbor_df_closeup = ice_harbor_df[(ice_harbor_df['date'] >= f'{closeup_year}-08-01') & (ice_harbor_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_closeup = pd.merge(mcnary_df_closeup, priest_rapids_df_closeup, on='date', suffixes=('_mcn', '_prd'), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with month-day on x-axis\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "ax[0].bar(combined_closeup['date'], combined_closeup['chinook_mcn'], label='McNary', width=5)\n",
    "ax[0].bar(combined_closeup['date'], combined_closeup['chinook_prd'], label='Priest Rapids', width=3)\n",
    "ax[0].set_ylabel('Fish count')\n",
    "ax[0].set_xlabel('Date')\n",
    "\n",
    "ax[0].set_xticks(combined_closeup['date'])\n",
    "ax[0].set_xticklabels(combined_closeup['date'].dt.strftime('%m-%d'))\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "prp_mcn_ratio = combined_closeup['chinook_prd'] / combined_closeup['chinook_mcn'] *100\n",
    "# put the values on top of the bars\n",
    "ax[1].bar(combined_closeup['date'], prp_mcn_ratio, width=4)\n",
    "ax[1].set_ylabel('Ratio (%)')\n",
    "ax[1].set_xlabel('Date')\n",
    "\n",
    "ax[1].set_xticks(combined_closeup['date'])\n",
    "ax[1].set_xticklabels(combined_closeup['date'].dt.strftime('%m-%d'))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thorr_df = pd.read_csv(proj_dir / \"Data/database/thorr_data.csv\")\n",
    "thorr_df['date'] = pd.to_datetime(thorr_df['Date'])\n",
    "\n",
    "thorr_df = thorr_df[thorr_df['RiverID'] == 9].copy()\n",
    "thorr_df_closeup = thorr_df[(thorr_df['date'] >= f'{closeup_year}-08-01') & (thorr_df['date'] <= f'{closeup_year}-11-15')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_closeup = thorr_df_closeup.groupby('RKm')\n",
    "\n",
    "merged_thorr = pd.DataFrame(columns=['date'])\n",
    "for group in grouped_closeup:\n",
    "    resampled = group[1].resample('W', on='date').mean(numeric_only=True).reset_index()\n",
    "    # print(resampled)\n",
    "    resampled.rename(columns={'EstTempC': resampled['RKm'].iloc[0]}, inplace=True)\n",
    "    merged_thorr = pd.merge(merged_thorr, resampled[['date', resampled['RKm'].iloc[0]]], on='date', how='outer')\n",
    "\n",
    "merged_thorr['date'] = pd.to_datetime(merged_thorr['date'])\n",
    "\n",
    "#make date the index\n",
    "merged_thorr.set_index('date', inplace=True)\n",
    "# sort by date\n",
    "merged_thorr.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_merge = merged_thorr.transpose()\n",
    "# transposed_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkm_450_640 = transposed_merge.loc[450:640]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "for date in rkm_450_640.columns:\n",
    "    if date >= pd.to_datetime(f'{closeup_year}-09-01') and date <= pd.to_datetime(f'{closeup_year}-10-20'):\n",
    "        ax.plot(rkm_450_640.index, rkm_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "    # ax.plot(rkm_450_640.index, rkm_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "\n",
    "ax.axhline(y=20, color='r', linestyle='--')\n",
    "# put the legend outside the plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_ylabel('Temperature (C)')\n",
    "ax.set_xlabel('River Kilometer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_450_640 = deviation_df[(deviation_df['Date'] >= f'{closeup_year}-08-01') & (deviation_df['Date'] <= f'{closeup_year}-11-15')].copy()\n",
    "# deviation_450_640.set_index('Date', inplace=True).reset_index()\n",
    "deviation_450_640 = deviation_450_640.set_index('Date')\n",
    "deviation_450_640 = deviation_450_640.sort_index()\n",
    "deviation_450_640 = deviation_450_640.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "for date in deviation_450_640.columns:\n",
    "    if date >= pd.to_datetime(f'{closeup_year}-09-01') and date <= pd.to_datetime(f'{closeup_year}-10-15'):\n",
    "        ax.plot(deviation_450_640.index, deviation_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "\n",
    "\n",
    "# put the legend outside the plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_ylabel('Temperature anormaly (C)')\n",
    "ax.set_xlabel('River Kilometer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeup_year = 2013\n",
    "mcnary_df_closeup = mcnary_df[(mcnary_df['date'] >= f'{closeup_year}-08-01') & (mcnary_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "priest_rapids_df_closeup = priest_rapids_df[(priest_rapids_df['date'] >= f'{closeup_year}-08-01') & (priest_rapids_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "prosser_df_closeup = prosser_df[(prosser_df['date'] >= f'{closeup_year}-08-01') & (prosser_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "ice_harbor_df_closeup = ice_harbor_df[(ice_harbor_df['date'] >= f'{closeup_year}-08-01') & (ice_harbor_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_closeup = pd.merge(mcnary_df_closeup, priest_rapids_df_closeup, on='date', suffixes=('_mcn', '_prd'), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with month-day on x-axis\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "ax[0].bar(combined_closeup['date'], combined_closeup['chinook_mcn'], label='McNary', width=5)\n",
    "ax[0].bar(combined_closeup['date'], combined_closeup['chinook_prd'], label='Priest Rapids', width=3)\n",
    "ax[0].set_ylabel('Fish count')\n",
    "ax[0].set_xlabel('Date')\n",
    "\n",
    "ax[0].set_xticks(combined_closeup['date'])\n",
    "ax[0].set_xticklabels(combined_closeup['date'].dt.strftime('%m-%d'))\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "prp_mcn_ratio = combined_closeup['chinook_prd'] / combined_closeup['chinook_mcn'] *100\n",
    "# put the values on top of the bars\n",
    "ax[1].bar(combined_closeup['date'], prp_mcn_ratio, width=4)\n",
    "ax[1].set_ylabel('Ratio (%)')\n",
    "ax[1].set_xlabel('Date')\n",
    "\n",
    "ax[1].set_xticks(combined_closeup['date'])\n",
    "ax[1].set_xticklabels(combined_closeup['date'].dt.strftime('%m-%d'))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "thorr_df = pd.read_csv(proj_dir / \"Data/database/thorr_data.csv\")\n",
    "thorr_df['date'] = pd.to_datetime(thorr_df['Date'])\n",
    "\n",
    "thorr_df = thorr_df[thorr_df['RiverID'] == 9].copy()\n",
    "thorr_df_closeup = thorr_df[(thorr_df['date'] >= f'{closeup_year}-08-01') & (thorr_df['date'] <= f'{closeup_year}-11-15')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_closeup = thorr_df_closeup.groupby('RKm')\n",
    "\n",
    "merged_thorr = pd.DataFrame(columns=['date'])\n",
    "for group in grouped_closeup:\n",
    "    resampled = group[1].resample('W', on='date').mean(numeric_only=True).reset_index()\n",
    "    # print(resampled)\n",
    "    resampled.rename(columns={'EstTempC': resampled['RKm'].iloc[0]}, inplace=True)\n",
    "    merged_thorr = pd.merge(merged_thorr, resampled[['date', resampled['RKm'].iloc[0]]], on='date', how='outer')\n",
    "\n",
    "merged_thorr['date'] = pd.to_datetime(merged_thorr['date'])\n",
    "\n",
    "#make date the index\n",
    "merged_thorr.set_index('date', inplace=True)\n",
    "# sort by date\n",
    "merged_thorr.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_merge = merged_thorr.transpose()\n",
    "# transposed_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkm_450_640 = transposed_merge.loc[450:640]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "for date in rkm_450_640.columns:\n",
    "    if date >= pd.to_datetime(f'{closeup_year}-09-01') and date <= pd.to_datetime(f'{closeup_year}-10-20'):\n",
    "        ax.plot(rkm_450_640.index, rkm_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "    # ax.plot(rkm_450_640.index, rkm_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "\n",
    "ax.axhline(y=20, color='r', linestyle='--')\n",
    "# put the legend outside the plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_ylabel('Temperature (C)')\n",
    "ax.set_xlabel('River Kilometer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_450_640 = deviation_df[(deviation_df['Date'] >= f'{closeup_year}-08-01') & (deviation_df['Date'] <= f'{closeup_year}-11-15')].copy()\n",
    "# deviation_450_640.set_index('Date', inplace=True).reset_index()\n",
    "deviation_450_640 = deviation_450_640.set_index('Date')\n",
    "deviation_450_640 = deviation_450_640.sort_index()\n",
    "deviation_450_640 = deviation_450_640.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "for date in deviation_450_640.columns:\n",
    "    if date >= pd.to_datetime(f'{closeup_year}-09-01') and date <= pd.to_datetime(f'{closeup_year}-10-15'):\n",
    "        ax.plot(deviation_450_640.index, deviation_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "\n",
    "\n",
    "# put the legend outside the plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_ylabel('Temperature anormaly (C)')\n",
    "ax.set_xlabel('River Kilometer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeup_year = 2002\n",
    "mcnary_df_closeup = mcnary_df[(mcnary_df['date'] >= f'{closeup_year}-08-01') & (mcnary_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "priest_rapids_df_closeup = priest_rapids_df[(priest_rapids_df['date'] >= f'{closeup_year}-08-01') & (priest_rapids_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "prosser_df_closeup = prosser_df[(prosser_df['date'] >= f'{closeup_year}-08-01') & (prosser_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "ice_harbor_df_closeup = ice_harbor_df[(ice_harbor_df['date'] >= f'{closeup_year}-08-01') & (ice_harbor_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_closeup = pd.merge(mcnary_df_closeup, priest_rapids_df_closeup, on='date', suffixes=('_mcn', '_prd'), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with month-day on x-axis\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "ax[0].bar(combined_closeup['date'], combined_closeup['chinook_mcn'], label='McNary', width=5)\n",
    "ax[0].bar(combined_closeup['date'], combined_closeup['chinook_prd'], label='Priest Rapids', width=3)\n",
    "ax[0].set_ylabel('Fish count')\n",
    "ax[0].set_xlabel('Date')\n",
    "\n",
    "ax[0].set_xticks(combined_closeup['date'])\n",
    "ax[0].set_xticklabels(combined_closeup['date'].dt.strftime('%m-%d'))\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "prp_mcn_ratio = combined_closeup['chinook_prd'] / combined_closeup['chinook_mcn'] *100\n",
    "# put the values on top of the bars\n",
    "ax[1].bar(combined_closeup['date'], prp_mcn_ratio, width=4)\n",
    "ax[1].set_ylabel('Ratio (%)')\n",
    "ax[1].set_xlabel('Date')\n",
    "\n",
    "ax[1].set_xticks(combined_closeup['date'])\n",
    "ax[1].set_xticklabels(combined_closeup['date'].dt.strftime('%m-%d'))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "thorr_df = pd.read_csv(proj_dir / \"Data/database/thorr_data.csv\")\n",
    "thorr_df['date'] = pd.to_datetime(thorr_df['Date'])\n",
    "\n",
    "thorr_df = thorr_df[thorr_df['RiverID'] == 9].copy()\n",
    "thorr_df_closeup = thorr_df[(thorr_df['date'] >= f'{closeup_year}-08-01') & (thorr_df['date'] <= f'{closeup_year}-11-15')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_closeup = thorr_df_closeup.groupby('RKm')\n",
    "\n",
    "merged_thorr = pd.DataFrame(columns=['date'])\n",
    "for group in grouped_closeup:\n",
    "    resampled = group[1].resample('W', on='date').mean(numeric_only=True).reset_index()\n",
    "    # print(resampled)\n",
    "    resampled.rename(columns={'EstTempC': resampled['RKm'].iloc[0]}, inplace=True)\n",
    "    merged_thorr = pd.merge(merged_thorr, resampled[['date', resampled['RKm'].iloc[0]]], on='date', how='outer')\n",
    "\n",
    "merged_thorr['date'] = pd.to_datetime(merged_thorr['date'])\n",
    "\n",
    "#make date the index\n",
    "merged_thorr.set_index('date', inplace=True)\n",
    "# sort by date\n",
    "merged_thorr.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_merge = merged_thorr.transpose()\n",
    "# transposed_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkm_450_640 = transposed_merge.loc[450:640]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "for date in rkm_450_640.columns:\n",
    "    if date >= pd.to_datetime(f'{closeup_year}-09-01') and date <= pd.to_datetime(f'{closeup_year}-10-20'):\n",
    "        ax.plot(rkm_450_640.index, rkm_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "    # ax.plot(rkm_450_640.index, rkm_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "\n",
    "ax.axhline(y=20, color='r', linestyle='--')\n",
    "# put the legend outside the plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_ylabel('Temperature (C)')\n",
    "ax.set_xlabel('River Kilometer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_450_640 = deviation_df[(deviation_df['Date'] >= f'{closeup_year}-08-01') & (deviation_df['Date'] <= f'{closeup_year}-11-15')].copy()\n",
    "# deviation_450_640.set_index('Date', inplace=True).reset_index()\n",
    "deviation_450_640 = deviation_450_640.set_index('Date')\n",
    "deviation_450_640 = deviation_450_640.sort_index()\n",
    "deviation_450_640 = deviation_450_640.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "for date in deviation_450_640.columns:\n",
    "    if date >= pd.to_datetime(f'{closeup_year}-09-01') and date <= pd.to_datetime(f'{closeup_year}-10-15'):\n",
    "        ax.plot(deviation_450_640.index, deviation_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "\n",
    "\n",
    "# put the legend outside the plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_ylabel('Temperature anormaly (C)')\n",
    "ax.set_xlabel('River Kilometer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeup_year = 2015\n",
    "mcnary_df_closeup = mcnary_df[(mcnary_df['date'] >= f'{closeup_year}-08-01') & (mcnary_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "priest_rapids_df_closeup = priest_rapids_df[(priest_rapids_df['date'] >= f'{closeup_year}-08-01') & (priest_rapids_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "prosser_df_closeup = prosser_df[(prosser_df['date'] >= f'{closeup_year}-08-01') & (prosser_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()\n",
    "ice_harbor_df_closeup = ice_harbor_df[(ice_harbor_df['date'] >= f'{closeup_year}-08-01') & (ice_harbor_df['date'] <= f'{closeup_year}-11-15')].resample('W', on='date').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_closeup = pd.merge(mcnary_df_closeup, priest_rapids_df_closeup, on='date', suffixes=('_mcn', '_prd'), how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with month-day on x-axis\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "ax[0].bar(combined_closeup['date'], combined_closeup['chinook_mcn'], label='McNary', width=5)\n",
    "ax[0].bar(combined_closeup['date'], combined_closeup['chinook_prd'], label='Priest Rapids', width=3)\n",
    "ax[0].set_ylabel('Fish count')\n",
    "ax[0].set_xlabel('Date')\n",
    "\n",
    "ax[0].set_xticks(combined_closeup['date'])\n",
    "ax[0].set_xticklabels(combined_closeup['date'].dt.strftime('%m-%d'))\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "prp_mcn_ratio = combined_closeup['chinook_prd'] / combined_closeup['chinook_mcn'] *100\n",
    "# put the values on top of the bars\n",
    "ax[1].bar(combined_closeup['date'], prp_mcn_ratio, width=4)\n",
    "ax[1].set_ylabel('Ratio (%)')\n",
    "ax[1].set_xlabel('Date')\n",
    "\n",
    "ax[1].set_xticks(combined_closeup['date'])\n",
    "ax[1].set_xticklabels(combined_closeup['date'].dt.strftime('%m-%d'))\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "thorr_df = pd.read_csv(proj_dir / \"Data/database/thorr_data.csv\")\n",
    "thorr_df['date'] = pd.to_datetime(thorr_df['Date'])\n",
    "\n",
    "thorr_df = thorr_df[thorr_df['RiverID'] == 9].copy()\n",
    "thorr_df_closeup = thorr_df[(thorr_df['date'] >= f'{closeup_year}-08-01') & (thorr_df['date'] <= f'{closeup_year}-11-15')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_closeup = thorr_df_closeup.groupby('RKm')\n",
    "\n",
    "merged_thorr = pd.DataFrame(columns=['date'])\n",
    "for group in grouped_closeup:\n",
    "    resampled = group[1].resample('W', on='date').mean(numeric_only=True).reset_index()\n",
    "    # print(resampled)\n",
    "    resampled.rename(columns={'EstTempC': resampled['RKm'].iloc[0]}, inplace=True)\n",
    "    merged_thorr = pd.merge(merged_thorr, resampled[['date', resampled['RKm'].iloc[0]]], on='date', how='outer')\n",
    "\n",
    "merged_thorr['date'] = pd.to_datetime(merged_thorr['date'])\n",
    "\n",
    "#make date the index\n",
    "merged_thorr.set_index('date', inplace=True)\n",
    "# sort by date\n",
    "merged_thorr.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_merge = merged_thorr.transpose()\n",
    "# transposed_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rkm_450_640 = transposed_merge.loc[450:640]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "for date in rkm_450_640.columns:\n",
    "    if date >= pd.to_datetime(f'{closeup_year}-09-01') and date <= pd.to_datetime(f'{closeup_year}-10-20'):\n",
    "        ax.plot(rkm_450_640.index, rkm_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "    # ax.plot(rkm_450_640.index, rkm_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "\n",
    "ax.axhline(y=20, color='r', linestyle='--')\n",
    "# put the legend outside the plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_ylabel('Temperature (C)')\n",
    "ax.set_xlabel('River Kilometer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_450_640 = deviation_df[(deviation_df['Date'] >= f'{closeup_year}-08-01') & (deviation_df['Date'] <= f'{closeup_year}-11-15')].copy()\n",
    "# deviation_450_640.set_index('Date', inplace=True).reset_index()\n",
    "deviation_450_640 = deviation_450_640.set_index('Date')\n",
    "deviation_450_640 = deviation_450_640.sort_index()\n",
    "deviation_450_640 = deviation_450_640.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "for date in deviation_450_640.columns:\n",
    "    if date >= pd.to_datetime(f'{closeup_year}-09-01') and date <= pd.to_datetime(f'{closeup_year}-10-15'):\n",
    "        ax.plot(deviation_450_640.index, deviation_450_640[date], label=f'{date.strftime(\"%m-%d\")}', marker='o')\n",
    "\n",
    "\n",
    "# put the legend outside the plot\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_ylabel('Temperature anormaly (C)')\n",
    "ax.set_xlabel('River Kilometer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def migration_stats(df, date_col='date', fish_col='chinook', start_month=8, start_day=1, end_month=11, end_day=15):\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "    df['year'] = df[date_col].dt.year\n",
    "    df['month'] = df[date_col].dt.month\n",
    "    df['day'] = df[date_col].dt.day\n",
    "\n",
    "    df = df.dropna(subset=[fish_col])\n",
    "\n",
    "    # group bon_df by year and plot\n",
    "    grouped = df.groupby('year')\n",
    "\n",
    "    stats_df = pd.DataFrame(columns=['year', 'start_date', 'end_date', 'total_fish', 'daily_mean', 'max_count', '5th_percentile', '5th_date', '25th_percentile', '25th_date', '50th_percentile', '50th_date', '75th_percentile', '75th_date', '95th_percentile', '95th_date'])\n",
    "\n",
    "    for name, group in grouped:\n",
    "        stats_dict = {}\n",
    "        run_start = pd.Timestamp(f\"{name}-{start_month}-{start_day}\")\n",
    "        run_end = pd.Timestamp(f\"{name}-{end_month}-{end_day}\")\n",
    "\n",
    "        run_df = group[(group[date_col] >= run_start) & (group[date_col] <= run_end)]\n",
    "        run_df = run_df.sort_values(by=date_col) # sort run_df by date\n",
    "        \n",
    "        total_fish = run_df[fish_col].sum()\n",
    "        # daily mean which is the total fish divided by the number of days from start to end\n",
    "        daily_mean = total_fish / (run_end - run_start).days\n",
    "        max_count = run_df[fish_col].max()\n",
    "\n",
    "\n",
    "        stats_dict['year'] = name\n",
    "        stats_dict['start_date'] = run_start\n",
    "        stats_dict['end_date'] = run_end\n",
    "        stats_dict['total_fish'] = total_fish\n",
    "        stats_dict['daily_mean'] = daily_mean\n",
    "        stats_dict['max_count'] = max_count\n",
    "\n",
    "        # TODO: find a better way to calculate percentiles\n",
    "        fish_sum = 0\n",
    "        for i, row in run_df.iterrows():\n",
    "            fish_sum += row[fish_col]\n",
    "            \n",
    "            if fish_sum >= total_fish * 0.05:\n",
    "                stats_dict['5th_percentile'] = fish_sum\n",
    "                stats_dict['5th_date'] = row[date_col]\n",
    "                break\n",
    "\n",
    "        fish_sum = 0\n",
    "\n",
    "        for i, row in run_df.iterrows():\n",
    "            fish_sum += row[fish_col]\n",
    "            \n",
    "            if fish_sum >= total_fish * 0.25:\n",
    "                stats_dict['25th_percentile'] = fish_sum\n",
    "                stats_dict['25th_date'] = row[date_col]\n",
    "                break\n",
    "\n",
    "        fish_sum = 0\n",
    "\n",
    "        for i, row in run_df.iterrows():\n",
    "            fish_sum += row[fish_col]\n",
    "            \n",
    "            if fish_sum >= total_fish * 0.50:\n",
    "                stats_dict['50th_percentile'] = fish_sum\n",
    "                stats_dict['50th_date'] = row[date_col]\n",
    "                break\n",
    "\n",
    "        fish_sum = 0\n",
    "\n",
    "        for i, row in run_df.iterrows():\n",
    "            fish_sum += row[fish_col]\n",
    "            \n",
    "            if fish_sum >= total_fish * 0.75:\n",
    "                stats_dict['75th_percentile'] = fish_sum\n",
    "                stats_dict['75th_date'] = row[date_col]\n",
    "                break\n",
    "\n",
    "        fish_sum = 0\n",
    "\n",
    "        for i, row in run_df.iterrows():\n",
    "            fish_sum += row[fish_col]\n",
    "            \n",
    "            if fish_sum >= total_fish * 0.95:\n",
    "                stats_dict['95th_percentile'] = fish_sum\n",
    "                stats_dict['95th_date'] = row[date_col]\n",
    "                break\n",
    "\n",
    "        stats_df = pd.concat([stats_df, pd.DataFrame(stats_dict, index=[0])])\n",
    "\n",
    "    return stats_df\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnary_stats_df = migration_stats(mcnary_df, start_month=8, start_day=9, end_month=10, end_day=31)\n",
    "priest_rapids_stats_df = migration_stats(priest_rapids_df, start_month=8, start_day=14, end_month=11, end_day=15)\n",
    "prosser_stats_df = migration_stats(prosser_df, start_month=8, start_day=16, end_month=12, end_day=28)\n",
    "ice_harbor_stats_df = migration_stats(ice_harbor_df, start_month=8, start_day=12, end_month=12, end_day=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out 2020 to 2023\n",
    "mcnary_df_ = mcnary_df[(mcnary_df['date'].dt.year >= 2013) & (mcnary_df['date'].dt.year <= 2018)]\n",
    "priest_rapids_df_ = priest_rapids_df[(priest_rapids_df['date'].dt.year >= 2013) & (priest_rapids_df['date'].dt.year <= 2018)]\n",
    "prosser_df_ = prosser_df[(prosser_df['date'].dt.year >= 2013) & (prosser_df['date'].dt.year <= 2018)]\n",
    "ice_harbor_df_ = ice_harbor_df[(ice_harbor_df['date'].dt.year >= 2013) & (ice_harbor_df['date'].dt.year <= 2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(15, 5), sharex=True)\n",
    "fig, axs = plt.subplots(4, 1, figsize=(15, 5), sharex=True)\n",
    "mcnary_df_.plot(x='date', y=['chinook'], style='-', ax=axs[0], title='McNary Dam')\n",
    "ice_harbor_df_.plot(x='date', y=['chinook'], style='-', ax=axs[1], title='Ice Harbor Dam')\n",
    "priest_rapids_df_.plot(x='date', y=['chinook'], style='-', ax=axs[2], title='Priest Rapids Dam')\n",
    "prosser_df_.plot(x='date', y=['chinook'], style='-', ax=axs[3], title='Prosser Dam')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(10, 10), sharey=True)\n",
    "for i, (stats_df, loc) in enumerate(zip([mcnary_stats_df, priest_rapids_stats_df, prosser_stats_df, ice_harbor_stats_df], ['McNary', 'Priest Rapids', 'Prosser', 'Ice Harbor'])):\n",
    "    print(i)\n",
    "    boxes = []\n",
    "    for j, row in stats_df.iterrows():\n",
    "        \n",
    "        boxes.append(\n",
    "            {\n",
    "                \"label\": f\"{row['year']}\",\n",
    "                \"whislo\": (row['5th_date'] -row[\"start_date\"]).days,  # Bottom whisker position\n",
    "                \"q1\": (row['25th_date'] -row[\"start_date\"]).days,  # First quartile (25th percentile)\n",
    "                \"med\": (row['50th_date'] -row[\"start_date\"]).days,  # Median         (50th percentile)\n",
    "                \"q3\": (row['75th_date'] -row[\"start_date\"]).days,  # Third quartile (75th percentile)\n",
    "                \"whishi\": (row['95th_date'] -row[\"start_date\"]).days,  # Top whisker position\n",
    "                \"fliers\": [],  # Outliers\n",
    "            }\n",
    "        )\n",
    "\n",
    "    axs[i].bxp(boxes, showfliers=False, vert=False)\n",
    "    axs[i].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack bar plot of the total fish count except for McNary\n",
    "data_dict = {\n",
    "    \"McNary\": mcnary_stats_df[[\"year\", \"total_fish\"]].copy(),\n",
    "    \"Priest Rapids\": priest_rapids_stats_df[[\"year\", \"total_fish\"]].copy(),\n",
    "    \"Prosser\": prosser_stats_df[[\"year\", \"total_fish\"]].copy(),\n",
    "    \"Ice Harbor\": ice_harbor_stats_df[[\"year\", \"total_fish\"]].copy(),\n",
    "}\n",
    "\n",
    "merged_data = pd.merge(\n",
    "    data_dict[\"McNary\"],\n",
    "    data_dict[\"Priest Rapids\"],\n",
    "    on=\"year\",\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"_1\", \"_2\"),\n",
    ")\n",
    "merged_data = pd.merge(merged_data, data_dict[\"Prosser\"], on=\"year\", how=\"outer\")\n",
    "merged_data = pd.merge(\n",
    "    merged_data, data_dict[\"Ice Harbor\"], on=\"year\", how=\"outer\", suffixes=(\"_3\", \"_4\")\n",
    ")\n",
    "\n",
    "# fig, axs = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 7), sharex=True)\n",
    "axs = axs[::-1]\n",
    "\n",
    "locations = [\"Priest Rapids\", \"Ice Harbor\", \"Prosser\"]\n",
    "\n",
    "percentages = {\n",
    "    \"Priest Rapids\": merged_data[\"total_fish_2\"] / merged_data[\"total_fish_1\"] * 100,\n",
    "    \"Ice Harbor\": merged_data[\"total_fish_4\"] / merged_data[\"total_fish_1\"] * 100,\n",
    "    \"Prosser\": merged_data[\"total_fish_3\"] / merged_data[\"total_fish_1\"] * 100,\n",
    "}\n",
    "\n",
    "totals = {\n",
    "    \"Priest Rapids\": merged_data[\"total_fish_2\"],\n",
    "    \"Ice Harbor\": merged_data[\"total_fish_4\"],\n",
    "    \"Prosser\": merged_data[\"total_fish_3\"],\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    \"Priest Rapids\": \"[5] Priest Rapids\",\n",
    "    \"Ice Harbor\": \"[12] Ice Harbor\",\n",
    "    \"Prosser\": \"[16] Prosser\",\n",
    "}\n",
    "\n",
    "bottom = np.zeros(len(merged_data[:-1]))\n",
    "bottom_totals = np.zeros(len(merged_data[:-1]))\n",
    "\n",
    "for loc in locations:\n",
    "    p = axs[0].bar(\n",
    "        merged_data[\"year\"][:-1].values.astype(int),\n",
    "        percentages[loc][:-1].values.astype(int),\n",
    "        label=labels[loc],\n",
    "        bottom=bottom,\n",
    "    )\n",
    "    # axs[1].bar(merged_data['year'][:-1], totals[loc][:-1], label=loc, bottom=bottom_totals)\n",
    "    bottom += percentages[loc][:-1]\n",
    "    bottom_totals += totals[loc][:-1]\n",
    "\n",
    "    axs[0].bar_label(p, label_type=\"center\")\n",
    "\n",
    "axs[0].set_title(\"Percentage of fish count at upstream locations\")\n",
    "# axs[1].set_title(\"Total fish count at each location\")\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "axs[0].set_ylabel(\"Percentage of total fish count\")\n",
    "\n",
    "# axs[2].bar(merged_data['year'], merged_data['total_fish_1'], label='McNary')\n",
    "axs[1].bar(merged_data[\"year\"], merged_data[\"total_fish_1\"], label=\"McNary\")\n",
    "axs[1].set_title(\"Total Fall Adult Chinook count at [4] McNary Dam\")\n",
    "axs[1].set_ylabel(\"Total fish count\")\n",
    "\n",
    "# axs[1].set_xlim(2013, 2018)\n",
    "\n",
    "\n",
    "# species = (\n",
    "#     \"Adelie\\n $\\\\mu=$3700.66g\",\n",
    "#     \"Chinstrap\\n $\\\\mu=$3733.09g\",\n",
    "#     \"Gentoo\\n $\\\\mu=5076.02g$\",\n",
    "# )\n",
    "# weight_counts = {\n",
    "#     \"Below\": np.array([70, 31, 58]),\n",
    "#     \"Above\": np.array([82, 37, 66]),\n",
    "# }\n",
    "# width = 0.5\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# bottom = np.zeros(3)\n",
    "\n",
    "# for boolean, weight_count in weight_counts.items():\n",
    "#     p = axs[1].bar(species, weight_count, width, label=boolean, bottom=bottom)\n",
    "#     bottom += weight_count\n",
    "\n",
    "# axs[1].set_title(\"Number of penguins with above average body mass\")\n",
    "# axs[1].legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_510 = pd.read_csv(proj_dir / \"Code/notebooks/EDA/columbia_510.csv\")\n",
    "col_520 = pd.read_csv(proj_dir / \"Code/notebooks/EDA/columbia_520.csv\")\n",
    "col_470 = pd.read_csv(proj_dir / \"Code/notebooks/EDA/columbia_470bw.csv\")\n",
    "col_630 = pd.read_csv(proj_dir / \"Code/notebooks/EDA/columbia_630bw.csv\")\n",
    "sna_0 = pd.read_csv(proj_dir / \"Code/notebooks/EDA/snake_0.csv\")\n",
    "\n",
    "col_510.rename(columns={\"Date\": \"date\", \"WaterTemperature(C)\": \"col_510\"}, inplace=True)\n",
    "col_520.rename(columns={\"Date\": \"date\", \"WaterTemperature(C)\": \"col_520\"}, inplace=True)\n",
    "col_470.rename(columns={\"Date\": \"date\", \"WaterTemperature(C)\": \"col_470\"}, inplace=True)\n",
    "col_630.rename(columns={\"Date\": \"date\", \"WaterTemperature(C)\": \"col_630\"}, inplace=True)\n",
    "sna_0.rename(columns={\"Date\": \"date\", \"WaterTemperature(C)\": \"sna_0\"}, inplace=True)\n",
    "\n",
    "col_510['date'] = pd.to_datetime(col_510['date'])\n",
    "col_520['date'] = pd.to_datetime(col_520['date'])\n",
    "col_470['date'] = pd.to_datetime(col_470['date'])\n",
    "col_630['date'] = pd.to_datetime(col_630['date'])\n",
    "sna_0['date'] = pd.to_datetime(sna_0['date'])\n",
    "\n",
    "col_510['year'] = col_510['date'].dt.year\n",
    "col_520['year'] = col_520['date'].dt.year\n",
    "col_470['year'] = col_470['date'].dt.year\n",
    "col_630['year'] = col_630['date'].dt.year\n",
    "sna_0['year'] = sna_0['date'].dt.year\n",
    "\n",
    "col_510['month'] = col_510['date'].dt.month\n",
    "col_520['month'] = col_520['date'].dt.month\n",
    "col_470['month'] = col_470['date'].dt.month\n",
    "col_630['month'] = col_630['date'].dt.month\n",
    "sna_0['month'] = sna_0['date'].dt.month\n",
    "\n",
    "col_510['day'] = col_510['date'].dt.day\n",
    "col_520['day'] = col_520['date'].dt.day\n",
    "col_470['day'] = col_470['date'].dt.day\n",
    "col_630['day'] = col_630['date'].dt.day\n",
    "sna_0['day'] = sna_0['date'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.merge(col_510, col_520, on=['date', 'year', 'month', 'day'], how='outer')\n",
    "temp_df = pd.merge(temp_df, col_470, on=['date', 'year', 'month', 'day'], how='outer')\n",
    "temp_df = pd.merge(temp_df, col_630, on=['date', 'year', 'month', 'day'], how='outer')\n",
    "temp_df = pd.merge(temp_df, sna_0, on=['date', 'year', 'month', 'day'], how='outer')\n",
    "temp_df['week'] = temp_df['date'].dt.isocalendar().week\n",
    "\n",
    "# temp_df = temp_df[(temp_df['date'].dt.year >= 2000) & (temp_df['date'].dt.year <= 2009)]\n",
    "# temp_df = temp_df[(temp_df['date'].dt.year == 2000) | (temp_df['date'].dt.year == 2001) | (temp_df['date'].dt.year == 2002) | (temp_df['date'].dt.year == 2003) | (temp_df['date'].dt.year == 2004) | (temp_df['date'].dt.year == 2005) | (temp_df['date'].dt.year == 2006) | (temp_df['date'].dt.year == 2007) | (temp_df['date'].dt.year == 2008) | (temp_df['date'].dt.year == 2009)]\n",
    "temp_df = temp_df[(temp_df['date'].dt.year == 2000) | (temp_df['date'].dt.year == 2002) | (temp_df['date'].dt.year == 2008) | (temp_df['date'].dt.year == 2009) | (temp_df['date'].dt.year == 2014) | (temp_df['date'].dt.year == 2013) | (temp_df['date'].dt.year == 2015)]\n",
    "\n",
    "\n",
    "# filter out june to october\n",
    "\n",
    "temp_df = temp_df[(temp_df['month'] >= 6) & (temp_df['month'] <= 10)]\n",
    "# temp_df['diff'] = temp_df['col_510'] - temp_df['sna_0']\n",
    "temp_df['diff'] = temp_df['col_470'] - temp_df['col_630']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 5))\n",
    "# temp_df.plot(x='date', y=['col_510', 'sna_0'], style='-', title='Water temperature at different locations', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_grouped = temp_df.groupby('year')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "for name, group in fall_grouped:\n",
    "    group.plot(x='week', y='diff', ax=ax, label=name)\n",
    "    # group.plot(x='week', y='col_510', ax=ax[1], label=f\"{name} col_510\")\n",
    "    # group.plot(x='week', y='sna_0', ax=ax[1], label=f\"{name} sna_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "for name, group in fall_grouped:\n",
    "    group.plot(x='week', y='sna_0', ax=ax, label=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_analysis(stats_df1, stats_df2,):\n",
    "    # merge the two dataframes on year\n",
    "    merged_df = pd.merge(stats_df1, stats_df2, on='year', suffixes=('_1', '_2'), how='inner')\n",
    "\n",
    "    time_analysis_df = pd.DataFrame()\n",
    "\n",
    "    # calculate the difference between the two start dates\n",
    "    time_analysis_df['year'] = merged_df['year']\n",
    "    time_analysis_df['start_date_diff'] = (merged_df['start_date_2'] - merged_df['start_date_1']).dt.days\n",
    "    time_analysis_df['end_date_diff'] = (merged_df['end_date_2'] - merged_df['end_date_1']).dt.days\n",
    "    time_analysis_df['total_fish_diff'] = merged_df['total_fish_2'] - merged_df['total_fish_1']\n",
    "    time_analysis_df['5th_date_diff'] = (merged_df['5th_date_2'] - merged_df['5th_date_1']).dt.days\n",
    "    time_analysis_df['25th_date_diff'] = (merged_df['25th_date_2'] - merged_df['25th_date_1']).dt.days\n",
    "    time_analysis_df['50th_date_diff'] = (merged_df['50th_date_2'] - merged_df['50th_date_1']).dt.days\n",
    "    time_analysis_df['75th_date_diff'] = (merged_df['75th_date_2'] - merged_df['75th_date_1']).dt.days\n",
    "    time_analysis_df['95th_date_diff'] = (merged_df['95th_date_2'] - merged_df['95th_date_1']).dt.days\n",
    "\n",
    "    return time_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priest_rapids_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnary_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "priest_rapids_ta = time_analysis(mcnary_stats_df, priest_rapids_stats_df)\n",
    "prosser_ta = time_analysis(mcnary_stats_df, prosser_stats_df)\n",
    "ice_harbor_ta = time_analysis(mcnary_stats_df, ice_harbor_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "priest_rapids_ta.plot(x='year', y='start_date_diff', ax=ax,)\n",
    "priest_rapids_ta.plot(x='year', y='5th_date_diff', ax=ax, label='Priest Rapids')\n",
    "prosser_ta.plot(x='year', y='5th_date_diff', ax=ax, label='Prosser')\n",
    "ice_harbor_ta.plot(x='year', y='5th_date_diff', ax=ax, label='Ice Harbor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(15, 15))\n",
    "axs = axs.flatten()\n",
    "\n",
    "boxes = []\n",
    "for i, row in bon_stats_df.iterrows():\n",
    "    \n",
    "    boxes.append(\n",
    "        {\n",
    "            \"label\": f\"{row['year']}\",\n",
    "            \"whislo\": (row['5th_date'] -row[\"start_date\"]).days,  # Bottom whisker position\n",
    "            \"q1\": (row['25th_date'] -row[\"start_date\"]).days,  # First quartile (25th percentile)\n",
    "            \"med\": (row['50th_date'] -row[\"start_date\"]).days,  # Median         (50th percentile)\n",
    "            \"q3\": (row['75th_date'] -row[\"start_date\"]).days,  # Third quartile (75th percentile)\n",
    "            \"whishi\": (row['95th_date'] -row[\"start_date\"]).days,  # Top whisker position\n",
    "            \"fliers\": [],  # Outliers\n",
    "        }\n",
    "    )\n",
    "\n",
    "axs[0].bxp(boxes, showfliers=False, vert=False);\n",
    "axs[0].set_title(\"Chinook Fall Migration Timing\")\n",
    "\n",
    "# plot total fish count\n",
    "axs[1].barh(bon_stats_df['year'], bon_stats_df['total_fish'])\n",
    "axs[1].set_title(\"Total Fish Count\")\n",
    "axs[1].set_ylim(1998.5, 2024.5)\n",
    "\n",
    "# plot max count\n",
    "axs[2].barh(bon_stats_df['year'], bon_stats_df['max_count'])\n",
    "axs[2].set_title(\"Max Fish Count\")\n",
    "axs[2].set_ylim(1998.5, 2024.5)\n",
    "\n",
    "boxes = []\n",
    "for i, row in tda_stats_df.iterrows():\n",
    "    \n",
    "    boxes.append(\n",
    "        {\n",
    "            \"label\": f\"{row['year']}\",\n",
    "            \"whislo\": (row['5th_date'] -row[\"start_date\"]).days,  # Bottom whisker position\n",
    "            \"q1\": (row['25th_date'] -row[\"start_date\"]).days,  # First quartile (25th percentile)\n",
    "            \"med\": (row['50th_date'] -row[\"start_date\"]).days,  # Median         (50th percentile)\n",
    "            \"q3\": (row['75th_date'] -row[\"start_date\"]).days,  # Third quartile (75th percentile)\n",
    "            \"whishi\": (row['95th_date'] -row[\"start_date\"]).days,  # Top whisker position\n",
    "            \"fliers\": [],  # Outliers\n",
    "        }\n",
    "    )\n",
    "\n",
    "axs[3].bxp(boxes, showfliers=False, vert=False);\n",
    "axs[3].set_title(\"Chinook Fall Migration Timing\")\n",
    "\n",
    "# plot total fish count\n",
    "axs[4].barh(tda_stats_df['year'], tda_stats_df['total_fish'])\n",
    "axs[4].set_title(\"Total Fish Count\")\n",
    "axs[4].set_ylim(1998.5, 2024.5)\n",
    "\n",
    "# plot max count\n",
    "axs[5].barh(tda_stats_df['year'], tda_stats_df['max_count'])\n",
    "axs[5].set_title(\"Max Fish Count\")\n",
    "axs[5].set_ylim(1998.5, 2024.5)\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bon_tda_temp = pd.read_csv(proj_dir / \"Code/notebooks/EDA/bon-tda.csv\")\n",
    "bon_tda_temp['date'] = pd.to_datetime(bon_tda_temp['Date'])\n",
    "bon_tda_temp = bon_tda_temp[bon_tda_temp['date'].dt.year >= 1999].copy()\n",
    "\n",
    "bon_tda_temp['year'] = bon_tda_temp['date'].dt.year\n",
    "bon_tda_temp['month'] = bon_tda_temp['date'].dt.month\n",
    "bon_tda_temp['day'] = bon_tda_temp['date'].dt.day\n",
    "\n",
    "fish_dif = bon_stats_df['total_fish'] - tda_stats_df['total_fish']\n",
    "fish_dif_percent = (bon_stats_df['total_fish'] - tda_stats_df['total_fish']) / bon_stats_df['total_fish'] * 100\n",
    "\n",
    "lyl_percent = lyl_stats_df['total_fish'] / bon_stats_df['total_fish'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyl_stats_df.plot(x='year', y='total_fish', style='-')\n",
    "lyl_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyl_stats_df.plot(x='year', y='total_fish', style='-')\n",
    "lyl_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_temp = bon_tda_temp.groupby('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_temp['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each year, plot the temperature from August 1 to November 15\n",
    "fig, axs = plt.subplots(len(grouped_temp['year'].unique()), 1, figsize=(10, 1*len(grouped_temp['year'].unique())))\n",
    "\n",
    "for i, (name, group) in enumerate(grouped_temp):\n",
    "    axs[i].plot(group['date'], group['AvgTemp'])\n",
    "    axs[i].set_title(name)\n",
    "    axs[i].axvline(pd.Timestamp(f\"{name}-{fall_start_month}-{fall_start_day}\"), color='r', linestyle='--')\n",
    "    axs[i].axvline(pd.Timestamp(f\"{name}-{fall_end_month}-{fall_end_day}\"), color='r', linestyle='--')\n",
    "\n",
    "    axs[i].set_xlim(pd.Timestamp(f\"{name}-01-01\"), pd.Timestamp(f\"{name}-12-31\"))\n",
    "\n",
    "    # remove x-axis labels\n",
    "    axs[i].set_xticklabels([])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each year, plot the temperature from August 1 to November 15\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "years = []\n",
    "mean_fall_temp = []\n",
    "\n",
    "for i, (name, group) in enumerate(grouped_temp):\n",
    "\n",
    "    group['date'] = pd.to_datetime(group['date'])\n",
    "    group = group[(group['date']>f\"{name}-{fall_start_month}-{fall_start_day}\") & (group['date']<f\"{name}-{fall_end_month}-{fall_end_day}\")].copy()\n",
    "    group['year'] = group['date'].dt.year\n",
    "    group['month'] = group['date'].dt.month \n",
    "    group['day'] = group['date'].dt.day\n",
    "\n",
    "    group['time_elapsed'] = (group['date'] - pd.Timestamp(f\"{name}-{fall_start_month}-{fall_start_day}\")).dt.days\n",
    "\n",
    "    if not group.empty:\n",
    "        ax.scatter(name, group['AvgTemp'].mean(), label=name)\n",
    "        years.append(name)\n",
    "        mean_fall_temp.append(group['AvgTemp'].mean())\n",
    "\n",
    "        # print(group)\n",
    "\n",
    "    # # create a new date column that is this_year-month-day\n",
    "    # group['modified_date'] = pd.to_datetime(f\"2020-{group['month']}-{group['day']}\")\n",
    "    # ax.plot(group['modified_date'], group['AvgTemp'], label=name)\n",
    "\n",
    "\n",
    "\n",
    "    # # ax.axvline(pd.Timestamp(f\"{name}-{fall_start_month}-{fall_start_day}\"), color='r', linestyle='--')\n",
    "    # # ax.axvline(pd.Timestamp(f\"{name}-{fall_end_month}-{fall_end_day}\"), color='r', linestyle='--')\n",
    "\n",
    "    # # ax.set_xlim(pd.Timestamp(f\"{name}-01-01\"), pd.Timestamp(f\"{name}-12-31\"))\n",
    "\n",
    "    # # remove x-axis labels\n",
    "    # ax.set_xticklabels([])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fish count difference between BON and TDA\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 7.5), sharex=True)\n",
    "axs[0].bar(bon_stats_df['year'], fish_dif_percent)\n",
    "axs[0].set_title(\"Fish Count Difference (%)\")\n",
    "axs[0].set_ylabel(\"Percentage difference\")\n",
    "\n",
    "axs[1].bar(bon_stats_df['year'], fish_dif)\n",
    "axs[1].set_title(\"Fish Count Difference\")\n",
    "axs[1].set_ylabel(\" Count\")\n",
    "\n",
    "axs[2].plot(years, mean_fall_temp)\n",
    "axs[2].set_title(\"Mean Fall Temperature\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# plot duration and total fish annotated with the duration\n",
    "ax.scatter(stats_df['duration'], stats_df['total_fish'])\n",
    "for i, row in stats_df.iterrows():\n",
    "    ax.annotate(row['year'], (row['duration'], row['total_fish']))\n",
    "\n",
    "# ax.scatter(stats_df['duration'], stats_df['max_count'], color='r')\n",
    "# ax.scatter((stats_df['5th_date'] -stats_df[\"start_date\"]).dt.days, stats_df['total_fish'], color='b')\n",
    "# ax.set_ylim(0, .8e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# plot duration and total fish annotated with the duration\n",
    "# ax.scatter(stats_df['duration'], stats_df['total_fish'])\n",
    "# for i, row in stats_df.iterrows():\n",
    "#     ax.annotate(row['duration'], (row['duration'], row['total_fish']))\n",
    "\n",
    "# ax.scatter(stats_df['duration'], stats_df['max_count'], color='r')\n",
    "m = ax.scatter((stats_df['95th_date'] -stats_df[\"start_date\"]).dt.days,(stats_df['5th_date'] -stats_df[\"start_date\"]).dt.days, c=stats_df['total_fish'])\n",
    "# add colorbar\n",
    "cbar = fig.colorbar(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrothermal-history",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
